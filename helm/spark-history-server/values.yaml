# Default values for spark-history-server.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Common labels for all deployed resources. Use this to apply a set of labels to all resources that are deployed.
commonLabels: {}

# Common annotations for all deployed resources. Useful for tools that perform actions based on annotations.
commonAnnotations: {}

# Desired number of Spark History Server pods to run.
replicaCount: 1

# Desired name of the Spark History Server deployment.
deploymentName:

# Configuration for the Docker image to be used.
image:
  repository: quay.io/okdp/spark  # Docker image repository.
  pullPolicy: IfNotPresent       # Image pull policy.
  tag: "spark-3.5.1-scala-2.12-java-17-2024-04-04-1.0.0"  # Docker image tag.

# Secrets to be used for pulling images from private Docker registries.
imagePullSecrets: []

# Override for the `spark-history-server.fullname` template, maintains the release name.
nameOverride: ""

# Overrides the release name.
fullnameOverride: ""

# Service account configuration.
serviceAccount:
  create: false  # Whether to create a service account or not.
  name: "default"       # The name of the service account to use.
  annotations: {}  # Annotations to add to the service account.

# Additional volumes to be mounted.
extraVolumes: []

# Additional volume mounts.
extraVolumeMounts: []

# Security context for the pod.
podSecurityContext:
  seccompProfile:
    type: "RuntimeDefault"


# Security context for the container.
containerSecurityContext:
  runAsUser: 185
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: false
  capabilities:
    drop: ["ALL"]

# Update strategy for deployments.
updateStrategy:
  type: RollingUpdate

# Configuration for the Spark History Server.
config:
  # Name of the class implementing the application history backend.
  spark.history.provider: "org.apache.spark.deploy.history.FsHistoryProvider"

  # For the filesystem history provider, the URL to the directory containing application event logs to load.
  spark.history.fs.logDirectory: "file:/tmp/spark-events"

  # The period at which the filesystem history provider checks for new or updated logs.
  spark.history.fs.update.interval: "10s"

  # The number of applications to retain UI data for in the cache.
  spark.history.retainedApplications: 50

  # The number of applications to display on the history summary page.
  spark.history.ui.maxApplications: 2147483647 #Int.MaxValue

  # The port to which the web interface of the history server binds.
  spark.history.ui.port: 18080

  # Indicates whether the history server should use kerberos to login.
  spark.history.kerberos.enabled: false

  # Kerberos principal name for the History Server when kerberos is enabled.
  spark.history.kerberos.principal: ""

  # Location of the kerberos keytab file for the History Server when kerberos is enabled.
  spark.history.kerberos.keytab: ""

  # Specifies whether the History Server should periodically clean up event logs from storage.
  spark.history.fs.cleaner.enabled: false

  # Specifies how often the filesystem job history cleaner checks for files to delete.
  spark.history.fs.cleaner.interval: "1d"

  # Job history files older than this will be deleted when the cleaner runs.
  spark.history.fs.cleaner.maxAge: "7d"

  # Specifies the maximum number of files in the event log directory.
  spark.history.fs.cleaner.maxNum: 2147483647 #Int.MaxValue

  # How many bytes to parse at the end of log files looking for the end event.
  spark.history.fs.endEventReparseChunkSize: "1m"

  # Enable optimized handling of in-progress logs.
  spark.history.fs.inProgressOptimization.enabled: true

  # Specifies whether the History Server should periodically clean up driver logs.
  spark.history.fs.driverlog.cleaner.enabled: "spark.history.fs.cleaner.enabled"

  # Specifies how often the filesystem driver log cleaner checks for files to delete.
  spark.history.fs.driverlog.cleaner.interval: "spark.history.fs.cleaner.interval"

  # Driver log files older than this will be deleted when the cleaner runs.
  spark.history.fs.driverlog.cleaner.maxAge: "spark.history.fs.cleaner.maxAge"

  # Number of threads used by the history server to process event logs. Default to 25% of available cores
  #spark.history.fs.numReplayThreads:

  # Maximum disk usage for the local directory storing cached application history information.
  spark.history.store.maxDiskUsage: "10g"

  # Local directory where to cache application history data.
  spark.history.store.path: ""

  # Serializer for writing/reading UI objects to/from disk-based KV Store.
  spark.history.store.serializer: "JSON"

  # Specifies custom spark executor log URL for supporting external log service.
  spark.history.custom.executor.log.url: ""

  # Specifies whether to apply custom spark executor log URL to incomplete applications as well.
  spark.history.custom.executor.log.url.applyIncompleteApplication: true

  # The maximum number of event log files which will be retained as non-compacted.
  spark.history.fs.eventLog.rolling.maxFilesToRetain: 2147483647 #Int.MaxValue

  # Whether to use HybridStore as the store when parsing event logs.
  spark.history.store.hybridStore.enabled: false

  # Maximum memory space for HybridStore.
  spark.history.store.hybridStore.maxMemoryUsage: "2g"

  # Specifies a disk-based store used in hybrid store.
  spark.history.store.hybridStore.diskBackend: "ROCKSDB"

  # Specifies the batch size for updating new eventlog files.
  spark.history.fs.update.batchSize: 2147483647 #Int.MaxValue


# Priority class name for the Spark History Server pod.
priorityClassName: ""

# Additional labels for the Spark History Server pod.
podLabels: {}

# Additional annotations for the Spark History Server pod.
podAnnotations: {}

# Service configuration for the Spark History Server.
service:
  name:
  type: ClusterIP
  port: 18080
  nodePort: ""
  labels: {}
  annotations: {}
  loadBalancerSourceRanges: []
  httpPortName: http

# Ingress configuration for external access.
ingress:
  enabled: false
  name:
  ingressClassName: ""  # Specify the ingress class (Kubernetes >= 1.18).
  annotations: {}
  labels: {}
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: Prefix
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# Resource requests and limits for the Spark History Server pod.
resources: {}

# Node selector for pod scheduling.
nodeSelector: {}

# Tolerations for pod scheduling.
tolerations: {}

# Affinity for pod scheduling.
affinity: {}

# Topology spread constraints for even pod distribution.
topologySpreadConstraints: []

# Liveness probe for the Spark History Server container.
livenessProbe: {}

# Readiness probe for the Spark History Server container.
readinessProbe: {}

# Startup probe for the Spark History Server container.
startupProbe: {}

# Extra environment variables to pass to the container.
extraEnvs: []

# Environment variables from ConfigMap or Secret.
envFrom: []

# Lifecycle hooks for the Spark History Server container.
lifecycle: {}
